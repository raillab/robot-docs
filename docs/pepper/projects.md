---
id: pepper-projects
title: Projects
description: Recent projects using the Pepper robot.
sidebar_position: 3
---

# 📚 Research & Open-Source Projects Using Pepper

## 🔬 Featured Research

1. **A Hybrid SLAM and Object Recognition System for Pepper Robot**  
   Integrates ORB‑SLAM2 and SIFT/RANSAC object recognition for autonomous indoor mapping and perception.  
   🔗 [arXiv Paper](https://arxiv.org/abs/1903.00675) and [GitHub Code](https://github.com/PaolaArdon/Salt-Pepper)

2. **Setting Up Pepper For Autonomous Navigation And Personalized Interaction With Users**  
   Combines ROS navigation, cloud-based speech recognition, and facial recognition to enable speech-triggered, user-aware navigation.  
   🔗 [arXiv Paper](https://arxiv.org/abs/1704.04797)

3. **Upgrading Pepper’s Social Interaction with Advanced Hardware and Perception Enhancements**  
   Enhances Pepper with onboard Jetson GPU and RealSense camera, enabling real-time people detection and gaze estimation.  
   🔗 [arXiv Paper](https://arxiv.org/abs/2409.01036)

4. **Adapted Pepper**  
   Hardware mod that adds GPU and 3D camera (D435i) making Pepper capable of running OpenPose/YOLO onboard.  
   🔗 [arXiv Paper](https://arxiv.org/abs/2009.03648) 

---

## 🛠️ Noteworthy GitHub Projects

1. **pepperchat** (iLab Sweden)  
   Integrates OpenAI's ChatGPT with Pepper using NAOqi, enabling open-domain conversation.  
   🔗 [pepperchat GitHub](https://github.com/ilabsweden/pepperchat)

2. **pepper_robot** (ros-naoqi)  
   ROS meta-package offering basic Pepper control, drift fixes, and autonomy features via ROS wrappers.  
   🔗 [pepper_robot GitHub](https://github.com/ros-naoqi/pepper_robot)

3. **Pepper-Nao Basic Tutorial** (PenguinZhou)  
   Educational resource with Choregraphe and Python demos—includes vision, expression, and interaction samples.  
   🔗 [Pepper_Nao_Basic_Tutorial GitHub](https://github.com/PenguinZhou/Pepper_Nao_Basic_Tutorial)

4. **robotic-exercise-coach-pepper** (M4rtinR)  
   Demonstrates Pepper as a personal coach guiding squash and physiotherapy exercises using behavior trees.  
   🔗 [Robotic‑Exercise‑Coach‑Pepper GitHub](https://github.com/M4rtinR/Robotic-Exercise-Coach-Pepper) 

5. **Dialogue-Pepper-Robot** (Igor Lirussi)  
   Notebook + module offering open-domain conversational features using QI SDK and Java AIML backend.  
   🔗 [Dialogue-Pepper-Robot GitHub](https://github.com/igor-lirussi/Dialogue-Pepper-Robot)

6. **pepper_dcm_robot** (ros-naoqi)  
   Provides ROS 1 controllers enabling smooth joint trajectory control via Naoqi DCM or MoveIt integration.  
   🔗 [pepper_dcm_robot GitHub](https://github.com/ros-naoqi/pepper_dcm_robot) 

7. **pepper_virtual** (ros-naoqi)  
   Simulated Pepper in Gazebo with ROS controllers—great for offline testing and development.  
   🔗 [pepper_virtual GitHub](https://github.com/ros-naoqi/pepper_virtual)

---

## 🎯 How to Use These

- **Clone and adapt** demo code to your RAIL Lab Pepper environment.
- **Integrate research ideas** (e.g. SLAM, emotion-aware navigation) into your workflows.
- **Use ROS packages** to build autonomy stacks with SLAM, perception, and control.
- **Leverage conversational or coaching bots** to build engaging user interactions.

---

These resources offer a wealth of inspiration—from high-level research breakthroughs to hands-on robotics demos. Want help integrating any of these into the RAIL Lab environment?